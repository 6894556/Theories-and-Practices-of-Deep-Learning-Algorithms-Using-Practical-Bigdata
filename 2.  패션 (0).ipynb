{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2.  패션.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOKpTYzM0MX8PsGwL4dmUvc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["CNN으로 패션아이템 구분하기\n","\n","2022년 1월 6일 \n","김이룸"],"metadata":{"id":"ejUtLgATb-FM"}},{"cell_type":"markdown","source":["똑같은 필터를 쓰면 결과가 다같다.\n","필터가 다르면 결과도 다르다.\n","그래서 필터가 굉장히 중요함."],"metadata":{"id":"h0I9jrTggvv_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"z4inOynHT0pX"},"outputs":[],"source":["# 1번 셀\n","\n","# 패키지 수입\n","# 자동완성은 런 한번하고 서버 연결이 되야 그 후부터 작동한다.\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from time import time\n","\n","from keras.datasets import fashion_mnist # keras가 공유하는 데이터\n","from keras.models import Sequential # 인공신경망을 만들 적에 '순차적'으로 필요한 충들을 add하는 모델\n","from keras.utils import np_utils # 출력데이터 처리 : 1-hot incoding\n","\n","from keras.layers import Dense # fully-connected layer -> dense\n","from keras.layers import Flatten, Conv2D, MaxPool2D # convolution 2d \n","from keras.layers import InputLayer # 입력층\n","\n"]},{"cell_type":"code","source":["# 2번 셀\n","\n","# 하이퍼 파라미터\n","\n","MY_EPOCH = 10 # 반복학습 수\n","MY_BATCH = 500 # 매번 가져와서 계산하는 학습용 데이터 수 -> 6만개에서 my_batch만큼 sample을 처리하고 모든 학습데이터로 학습 할 때까지 한번에 마이배치만큼 학습시킴\n","# 한 배치당 한번 가중치 보정이 일어난다.\n","# BATCH란 무엇인가? 답 : 판서를 참고하라.\n","# 학습용 데이터 육만개\n","# CNN만들면 입력 주고 출력나온다.\n","# 샘플 하나가 이미지 한개다.\n","# 육만개를 동시에 불러와서 cnn으로 보내지 않는다.\n","# 버겁다 . 그래서 육만개 중 오백개씩 갖고와서 학습해서 cnn으로 보내고\n","# 6만개 다 학습할 때까지 오백개씩 끊어서 cnn으로 배달한다. -> 그럼 총 120번 배달하는건가?\n","# 배치사이즈는 너무 커도 안좋고 너무 작아도안좋다.\n","# 배치가 너무 크면 왜 안좋은가? 답 : 한번에 처리해야할 양이 너무 많다. 잘못하면 gpu 죽는다. gpu 낭비다.\n","# 배치가 너무 작으면 왜 안좋은가? 답 : 학습시간이 너무 오래걸린다. 배치가 2이면 배달을 3만번 해야한다.\n","# 배치사이즈는 무엇을 기준으로 결정한다? 답 : 본인 컴퓨터 사양에 맞게 결정한다.\n","# 하이퍼 파라메터 튜니이란 값이 바꿔보는 것을 의미한다. 튜닝은 학습시간과 mse에 영향을 미친다."],"metadata":{"id":"eqUbsIZmcPgm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 3번 셀\n","\n","# 데이터 불러오기\n","# 자르고 나누고 안해도 된다. 케라스가 다 해놓음.\n","# 순서 주의해라\n","\n","(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data() # 데이터 4분할 -> raw 보기 전에 바로 split 해버리네? \n","# 케라스가 만들어 놓은 것 다운로드 받으면 끝이다.\n","# 데이터 불러오면 모양부터 확인해라. 습관을 들여라. 특히 딥러닝할 때 반드시 필요함.\n","\n","# 데이터 모양확인\n","# print('학습용 입력 데이터 모양 : ', X_train.shape)\n","# 3차원 데이터\n","# 육만은 이미지 개수\n","# 두번째 28은 x축의 화소수\n","# 28은 y축의 화소수\n","# print('학습용 출력 데이터 모양 : ', Y_train.shape)\n","# print(X_train[0]) # 이게 첫번 째 사진 784 화소 데이터이다. 각각의 화소가 나타난 것 -> 화소값 나오는 행이다.\n","# 각각의 화소는 0부터 255까지의 범위를 갖는 정수값이다\n","# 0은 검은색 255는 하얀색, 100은 회색이다.\n","# 이는 몇비트 데이터인가? 255를 이진수로 전환하면 몇자리가 되는가? 답 : 8자리가 필요하다. 따라서 gray_scale은 8bit 데이터이다.\n","# 흑백사진이건 칼라사진이건 비트수를 봐야한다????\n","# 이진수 관련 판서를 참고하라. ex) 255 -> 11111111 -> 8bit image data\n","# 각화소는 0에서 255 사이의 정수값을 갖는다.\n","\n","plt.imshow(X_train[0]) # ankle boot 이미지가 나온다.'\n","# 위 팔레트를 바꿔보자\n","# plt.imshow(X_train[0], cmap='gray') # 이건 채널 하나다.\n","\n","# 칼라이미지는 채널 3개가 더 추가가된다.\n","# print('0번 학습용 이미지 라벨 : ', Y_train[0]) # y_train하면 육만개 나온다. 0번지 라벨만 봐보자.\n","# 9. 답은 숫자로 나온다. 그럼 9가 뭔가? 답 : ankle boots이다. mnist 패션 데이터 슬라이드 레전드 보면 부츠의 라벨이 9다.\n","\n","# lim's comment : 수치 데이터는 8-bit 화소 정수 [0,255]\n","\n","\n","print('학습용 입력 데이터 모양 : ', X_train.shape) \n","print('학습용 출력 데이터 모양 : ', Y_train.shape) # 라벨은 1차원 데이터다. 그래서 (60000,)\n","print('평가용 입력 데이터 모양 : ', X_test.shape) # \n","print('평가용 출력 데이터 모양 : ', Y_test.shape) # 실행 전 예측해봐라.\n","# 평가용 데이터는 10000개가 있다.\n","print(X_train[0].shape) # 2차원 데이터다 -> 2차원 데이터는 찍힌다.\n","print('0번 학습용 이미지 라벨 : ', Y_train[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"id":"sNxNXGPqe2RJ","executionInfo":{"status":"ok","timestamp":1641533644363,"user_tz":-540,"elapsed":899,"user":{"displayName":"IRUM KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12875629916024573944"}},"outputId":"8a34008e-66fe-4fe6-a5f8-6b371c4fb60f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["학습용 입력 데이터 모양 :  (60000, 28, 28)\n","학습용 출력 데이터 모양 :  (60000,)\n","평가용 입력 데이터 모양 :  (10000, 28, 28)\n","평가용 출력 데이터 모양 :  (10000,)\n","(28, 28)\n","0번 학습용 이미지 라벨 :  9\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["CNN으로 패션아이템 구분하기\n","\n","2022년 1월 7일 \n","김이룸"],"metadata":{"id":"xMchV9pWE_Kg"}},{"cell_type":"code","source":["# 4번 셀 \n","\n","# 입력 데이터 추가 처리\n","X_train = X_train / 255 #스케일링 위해 렐루 사용안해도 된다.# 이 행을 실행하면 화소가 어떻게 변할까? 화소데이터 스케일링 # 0-255 정수를 255로 나누면 0-1 수가 된다.\n","print(X_train[0]) # 모든 화소데이터가 0-1 사이의 값으로 스케일링되었음을 확인할 수 있다.\n","# 학습이 잘되서 화소데이터 스케일링을 한다.\n","# 정규화하는 이유는 하나가 너무 커서 튀는것을 방지하기 위한 처리였다.\n","# 이것도 같은 이유로 0-1로 확 줄여버리는 것이다.\n","# plt.imshow(X_train[0], cmap='gray') # 255로 나눈다고 다른 사진이 되는건아니다. 특징은 유지되면서 화소값만 낮아진 것이다.\n","X_test = X_test / 255\n","# 이로써 화소데이터 0-1 스케일링은 끝났다.\n","\n","\n","# 이미지 채널 정보 추가\n","print('전 : ', X_train.shape) # 이안에 데이터 다 있는데 왜 차원을 늘리는가? 답 : 은 다음과 같다.\n","# keras convolution (합성곱 ) 함수가 원해서 -> 4차원 입력을 함수가 요구한다. 그래서 차원을 확장한다. 컨볼루션에 입력하기 위해3차원에서 4차원으로 확장하는 방법.\n","X_train = np.expand_dims(X_train, axis=3) # 학습용 입력데이터를 3번 축으로 익스펜드 디멘션한다. axis=3은 우리가 추가하고자 하는 축을 의미한다. 3 축에 채널을 하나 추가해라.\n","# axis=3 은 채널 차원이라고 한다.\n","# 칼라이미지는 axis=3 값이 3이 된다. rgb 가 값이 3이라 그렇다. 나중에 얘기하자.\n","print('후 : ', X_train.shape)\n","print('전  : ', X_test.shape)\n","X_test = np.expand_dims(X_test, axis=3) # x_test도 스케일링. 이미지 채널 정보 axis=3 를 추가하는 것이다.\n","print('후 : ', X_test.shape)\n","\n","# 채널 수는 이미지 개수이다 ."],"metadata":{"id":"FKjjVsQOfLlU","executionInfo":{"status":"ok","timestamp":1641533644365,"user_tz":-540,"elapsed":17,"user":{"displayName":"IRUM KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12875629916024573944"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9c53284f-e138-45ae-ac2a-17c88b3927f4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.00392157 0.         0.         0.05098039 0.28627451 0.\n","  0.         0.00392157 0.01568627 0.         0.         0.\n","  0.         0.00392157 0.00392157 0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.01176471 0.         0.14117647 0.53333333 0.49803922 0.24313725\n","  0.21176471 0.         0.         0.         0.00392157 0.01176471\n","  0.01568627 0.         0.         0.01176471]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.02352941 0.         0.4        0.8        0.69019608 0.5254902\n","  0.56470588 0.48235294 0.09019608 0.         0.         0.\n","  0.         0.04705882 0.03921569 0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.60784314 0.9254902  0.81176471 0.69803922\n","  0.41960784 0.61176471 0.63137255 0.42745098 0.25098039 0.09019608\n","  0.30196078 0.50980392 0.28235294 0.05882353]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.00392157\n","  0.         0.27058824 0.81176471 0.8745098  0.85490196 0.84705882\n","  0.84705882 0.63921569 0.49803922 0.4745098  0.47843137 0.57254902\n","  0.55294118 0.34509804 0.6745098  0.25882353]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.00392157 0.00392157 0.00392157\n","  0.         0.78431373 0.90980392 0.90980392 0.91372549 0.89803922\n","  0.8745098  0.8745098  0.84313725 0.83529412 0.64313725 0.49803922\n","  0.48235294 0.76862745 0.89803922 0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.71764706 0.88235294 0.84705882 0.8745098  0.89411765\n","  0.92156863 0.89019608 0.87843137 0.87058824 0.87843137 0.86666667\n","  0.8745098  0.96078431 0.67843137 0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.75686275 0.89411765 0.85490196 0.83529412 0.77647059\n","  0.70588235 0.83137255 0.82352941 0.82745098 0.83529412 0.8745098\n","  0.8627451  0.95294118 0.79215686 0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.00392157 0.01176471 0.\n","  0.04705882 0.85882353 0.8627451  0.83137255 0.85490196 0.75294118\n","  0.6627451  0.89019608 0.81568627 0.85490196 0.87843137 0.83137255\n","  0.88627451 0.77254902 0.81960784 0.20392157]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.02352941 0.\n","  0.38823529 0.95686275 0.87058824 0.8627451  0.85490196 0.79607843\n","  0.77647059 0.86666667 0.84313725 0.83529412 0.87058824 0.8627451\n","  0.96078431 0.46666667 0.65490196 0.21960784]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.01568627 0.         0.\n","  0.21568627 0.9254902  0.89411765 0.90196078 0.89411765 0.94117647\n","  0.90980392 0.83529412 0.85490196 0.8745098  0.91764706 0.85098039\n","  0.85098039 0.81960784 0.36078431 0.        ]\n"," [0.         0.         0.00392157 0.01568627 0.02352941 0.02745098\n","  0.00784314 0.         0.         0.         0.         0.\n","  0.92941176 0.88627451 0.85098039 0.8745098  0.87058824 0.85882353\n","  0.87058824 0.86666667 0.84705882 0.8745098  0.89803922 0.84313725\n","  0.85490196 1.         0.30196078 0.        ]\n"," [0.         0.01176471 0.         0.         0.         0.\n","  0.         0.         0.         0.24313725 0.56862745 0.8\n","  0.89411765 0.81176471 0.83529412 0.86666667 0.85490196 0.81568627\n","  0.82745098 0.85490196 0.87843137 0.8745098  0.85882353 0.84313725\n","  0.87843137 0.95686275 0.62352941 0.        ]\n"," [0.         0.         0.         0.         0.07058824 0.17254902\n","  0.32156863 0.41960784 0.74117647 0.89411765 0.8627451  0.87058824\n","  0.85098039 0.88627451 0.78431373 0.80392157 0.82745098 0.90196078\n","  0.87843137 0.91764706 0.69019608 0.7372549  0.98039216 0.97254902\n","  0.91372549 0.93333333 0.84313725 0.        ]\n"," [0.         0.22352941 0.73333333 0.81568627 0.87843137 0.86666667\n","  0.87843137 0.81568627 0.8        0.83921569 0.81568627 0.81960784\n","  0.78431373 0.62352941 0.96078431 0.75686275 0.80784314 0.8745098\n","  1.         1.         0.86666667 0.91764706 0.86666667 0.82745098\n","  0.8627451  0.90980392 0.96470588 0.        ]\n"," [0.01176471 0.79215686 0.89411765 0.87843137 0.86666667 0.82745098\n","  0.82745098 0.83921569 0.80392157 0.80392157 0.80392157 0.8627451\n","  0.94117647 0.31372549 0.58823529 1.         0.89803922 0.86666667\n","  0.7372549  0.60392157 0.74901961 0.82352941 0.8        0.81960784\n","  0.87058824 0.89411765 0.88235294 0.        ]\n"," [0.38431373 0.91372549 0.77647059 0.82352941 0.87058824 0.89803922\n","  0.89803922 0.91764706 0.97647059 0.8627451  0.76078431 0.84313725\n","  0.85098039 0.94509804 0.25490196 0.28627451 0.41568627 0.45882353\n","  0.65882353 0.85882353 0.86666667 0.84313725 0.85098039 0.8745098\n","  0.8745098  0.87843137 0.89803922 0.11372549]\n"," [0.29411765 0.8        0.83137255 0.8        0.75686275 0.80392157\n","  0.82745098 0.88235294 0.84705882 0.7254902  0.77254902 0.80784314\n","  0.77647059 0.83529412 0.94117647 0.76470588 0.89019608 0.96078431\n","  0.9372549  0.8745098  0.85490196 0.83137255 0.81960784 0.87058824\n","  0.8627451  0.86666667 0.90196078 0.2627451 ]\n"," [0.18823529 0.79607843 0.71764706 0.76078431 0.83529412 0.77254902\n","  0.7254902  0.74509804 0.76078431 0.75294118 0.79215686 0.83921569\n","  0.85882353 0.86666667 0.8627451  0.9254902  0.88235294 0.84705882\n","  0.78039216 0.80784314 0.72941176 0.70980392 0.69411765 0.6745098\n","  0.70980392 0.80392157 0.80784314 0.45098039]\n"," [0.         0.47843137 0.85882353 0.75686275 0.70196078 0.67058824\n","  0.71764706 0.76862745 0.8        0.82352941 0.83529412 0.81176471\n","  0.82745098 0.82352941 0.78431373 0.76862745 0.76078431 0.74901961\n","  0.76470588 0.74901961 0.77647059 0.75294118 0.69019608 0.61176471\n","  0.65490196 0.69411765 0.82352941 0.36078431]\n"," [0.         0.         0.29019608 0.74117647 0.83137255 0.74901961\n","  0.68627451 0.6745098  0.68627451 0.70980392 0.7254902  0.7372549\n","  0.74117647 0.7372549  0.75686275 0.77647059 0.8        0.81960784\n","  0.82352941 0.82352941 0.82745098 0.7372549  0.7372549  0.76078431\n","  0.75294118 0.84705882 0.66666667 0.        ]\n"," [0.00784314 0.         0.         0.         0.25882353 0.78431373\n","  0.87058824 0.92941176 0.9372549  0.94901961 0.96470588 0.95294118\n","  0.95686275 0.86666667 0.8627451  0.75686275 0.74901961 0.70196078\n","  0.71372549 0.71372549 0.70980392 0.69019608 0.65098039 0.65882353\n","  0.38823529 0.22745098 0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.15686275 0.23921569 0.17254902 0.28235294 0.16078431\n","  0.1372549  0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.         0.         0.        ]]\n","전 :  (60000, 28, 28)\n","후 :  (60000, 28, 28, 1)\n","전  :  (10000, 28, 28)\n","후 :  (10000, 28, 28, 1)\n"]}]},{"cell_type":"code","source":["# 5번 셀\n","\n","# 출력 데이터  (=라벨) 추가 처리 : 원핫인코딩 처리\n","# 4번 셀에서는 입력데이터 추가 처리하였다.\n","print('before : ', Y_train[0])\n","Y_train = np_utils.to_categorical(Y_train, 10) # 뭐하는 건지 모르겠으면 전후를 찍어봐라. 범주형 데이터로 바구면 원핫인코딩 처리가 된거다.\n","print('after : ', Y_train[0]) # 1-hot encoding을 한 것임을 확인할 수 있다.\n","\n","# 패션데이터 라벨이 범주형 데이터인가? 답 : 맞다. 10개의 범주가 있다.\n","# 왜? 기계학습이 잘되니까. 10자리로 9를 표시한거다.\n","\n","\n","Y_test = np_utils.to_categorical(Y_test, 10) # 테스트도 동일한 처리를 해준다."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QUuFGijSHNfM","executionInfo":{"status":"ok","timestamp":1641533644366,"user_tz":-540,"elapsed":12,"user":{"displayName":"IRUM KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12875629916024573944"}},"outputId":"35482093-0718-4641-a970-74ea134a5e42"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["before :  9\n","after :  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"]}]},{"cell_type":"code","source":["# 6번 셀\n","\n","# 최종 데이터 모양 확인\n","# 처리가 끝난 데이터의 모양을 확인하느 습관을 들일 것.\n","print('학습용 입력 데이터 모양 : ', X_train.shape) # 실행 전에 예측해봐라. 채널 추가되었다.\n","print('학습용 출력 데이터 모양 : ', Y_train.shape) # 60000,10 : 원핫인코딩 되었다. 10은 원핫인코딩때문에 그렇다. 총 범주가 10개 카테고리 때문에 그렇다.\n","print('평가용 입력 데이터 모양 : ', X_test.shape) \n","print('평가용 출력 데이터 모양 : ', Y_test.shape) \n","\n","# 학습용 출력 60000,1에서 원핫통해  1이 아니라 10  -> 한자리 인덱스가 10자리 인덱스로 encoding되었으므로."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dMraBkmXKve0","executionInfo":{"status":"ok","timestamp":1641533644810,"user_tz":-540,"elapsed":451,"user":{"displayName":"IRUM KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12875629916024573944"}},"outputId":"d2998df8-79c9-4cf1-8b26-793d69e1d2ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["학습용 입력 데이터 모양 :  (60000, 28, 28, 1)\n","학습용 출력 데이터 모양 :  (60000, 10)\n","평가용 입력 데이터 모양 :  (10000, 28, 28, 1)\n","평가용 출력 데이터 모양 :  (10000, 10)\n"]}]},{"cell_type":"code","source":["# 7번 셀\n","\n","# 인공 신경망 구현 : CNN\n","# 여기서 합성곱이 무엇인지 이론이 시작된다.\n","# 컨볼루션 렐루 풀 반복적으로 사용된다.\n","\n","# 합성곱 계산을 어떻게 하는건지 아는가? 강의자료 / 추가자료를 참고하라.\n","# 원래 화소는 5곱5 사진이다. 인풋이미지.\n","# 합성곱은 필터가 필요해 \n","# 3곱3 필터를 사용한다. 필터는 인풋이미지보다 크기가 작아야함.\n","# 합성곱은 필터를 이미지에 올리는거다.\n","# 필터 올려놓은 부분이 짙은 회색이다.\n","# 왜 4일까? \n","# 학생답 1: 1이 겹치는 수\n","# 학생답 2: 각 셀의 곱의 합\n","# 교수님 답 : 곱하고 더하면 된다.\n","# 결과는 9개 나온다.\n","# 삼성의 엑스녹스 오토? 자율주행차에 반드시 필요한 반도체 -> 주로 합성곱을 한다. mac ; multiply and accumulate\n","# 삼성 ai 반도체 -> 합성곱에서 주로하는  연산이 뭔가? -> 곱하고 더하는 것. -> 어떻게 하면 더 잘할 수 있는가? -> 곱하고 더하는 걸 동시에 많이하면 더 잘할 수 있다.\n","# 가중치는 어디에 붙어있나? 답 : 필터에 붙어있다. 필터가 가중치다. 필터가 돈이다. 가중치 보정하면 필터안의 값들이 변한다. 필터의 숫자와 개이미지 개수와 같다.\n","# 네번째 개이미지는 왜 특징이 남아있지 않는가? 답 :네번째 그림은 실패했다. 필터가 학습이 덜되어서 네번째 개이미지는 특징이 남아있지 않은 것이다. 필터가 학습이 안되서 망한거다.\n","# 그러면 나머지 다섯개는 왜 특징을 잘뽑아내었는가? 답 : 필터가 학습이 잘되어서 특징이 잘뽑혔다. \n","# 컨볼루션이란\n","# 필터 한개를 개이미지에 적용하면 아홉개의 이미지가 생긴다.필터도 9개가 생긴다. \n","# 컨볼루션은 원본이미지가 망가진다. 화소수가 줄어든다. \n","# 수학적으로 증명은 못한다. 프랙티컬하게 못한다. 에이아이는 \n","# 합성곱에서 채널이란게 있다. 채널은 이미지의 수이다.\n","# 원본 사진은 이미지가 한개다. 칼라이미지는 채널이 세개다. 알쥐비.\n","# 이미지가 세개가 들어왔어. 출력은 하나로 만드려고 해. 어떻게 세개를 하나로 만들까? 답 : 필터 하나쓴다. 3층짜리 필터 하나쓴다. 입체필터다.입체필터 하나로 봐라.\n","# 입력 채널이 3이고 출력 채널이 1이라고하면 필터는 1개 쓴다. 3층짜리 필터 1개 쓴다.\n","# 입력 채널이 3이고 출력 채널이 2라고하면 필터는 2개 쓴다. 3층짜리 필터를 2개 쓴다.\n","# 필터의 높이는 입력채널의 수와 같다.\n","# 아웃풋 채널이 2면 필터 2개 필요하다. 아웃풋 패널이 n개면 필터 n개 필요하다.\n","# 출려개널의 개수는 사용한 필터의 개수와 똑같다. -> 필터를 몇개 사용했는가? 답 : 출력채널의 개수만큼 필터를 사용했다.\n","\n","#풀링할 때는 창의 사이즈 윈도우 사이즈가 필여ㅛ하다. 2곱하기 2창으로 하면 이미지를 창으로 나눈다. 각 창에서 숫자 네개 중 세개는 버리고 하나는 키핑을 한다.\n","# 풀링에서 필터가 필요한가? 답 : 필터 안쓴다. -> 필터는 어디서 사용하는가? 답 : 컨볼루션에서 필터를 사용한다.\n","# 풀링은 학습을 하는가요? 답 : 가중치 필요없고 학습안한다. -> 학습은 어디서 하는가? 답 : 컨볼루션에서 학습한다. 풀링에서는 학습하지 않는다.\n","# 풀링하면 데이터 퀄리티가 떨어진다. \n","# 맥스 풀링 : 창에서 가장 큰 값만 추출하고 나머지는 버린다.\n","# 5바이5 이미지 3바이3 필터로 합성곱 하면 3바이3으로 사이즈가 줄어든다. -> 3바이 3으로 사이즈가 줄어드는 대상을 정확히 무엇으로 보아야하는가? \n","# 이미지 사이즈 안줄이는 방법이 있다. padding을 추가하면 된다. \n","# 패딩처리 : 립력과 출력이미지의 크기를 동일하게 유지해준ㄷ. 이미지에 0으로 데두리를 추가한다.\n","# 왜 이미지 크기를 안줄이는가? 답 : 버리는건 풀링이하게하고 합성곱에서는 특징추출만 하게하자.\n","# 컨볼루션이 특징을 잘 뽑기 때문에 풀링이 필요없는거 다 버리는거다. 그래서 괜찮다. 추출하고 버리고, 추출하고 버리고.\n","# 대신 풀링을 너무 많이하면 안된다. 컨볼루션 두번에 풀링 한버.\n","# 합성곱은 학습도하고 필터도 필요하다. \n","\n","model = Sequential()\n","model.add(InputLayer(input_shape=(28,28,1))) # 입력층 add : 입력층 들어오는 사이즈만 지정, 들어오는 이미지의 데이터 모양\n","\n","# 첫번째 합성곱 '블럭'(컨볼루션, 풀링) 추가\n","model.add(Conv2D(filters=32, \n","                 kernel_size=2,\n","                 padding='same',\n","                 activation='relu')) # Conv2D : 합성곱, filters=사용할 필터개수(입력채널수와같다)몇개로 불릴거냐, kernel_size=필터사이즈, padding=same->컨볼루션해도 사이즈 축소하지마라는 옵샨\n","# 출력채널이 32개가 아니라 10개인데 사용할 필터개수를 32개로 정하는 이유는 무엇인가 ? \n","# Param # 이 160이 나와야 정상이다.\n","# 왜 160이 나왔는가?\n","# outputshape : 28곱28이미지가 32개가 생긴다\n","# kernel이 필터다. kernel_Size는 필터 사이즈다.\n","# padding='same' : 이미지 사이즈를 유지해준다.\n","# 필터 32개 넣어서 이미지를 32개로 늘렸어.\n","model.add(MaxPool2D(pool_size=2))# MaxPool2D : 풀링 , pool_size : 윈도우 사이즈 -> 만든사람 마음대로 이름지은 것.\n","# (None,행,열,채널)\n","# 왜 28바이28이미지가 14바이14이미ㅣㅈ로 떨어졌을까? 답 : 풀링했잖아.왜 하필 14인가? 답 : 풀사이즈가 2라서. CNN 설계도를 참고하라.\n","# 28바이28바이1에서 1은 : 채널수. 바꿔말하면 이미지 개수.\n","# 이미지 화소수는 변화가 없없다. 벗 채널수는 변화가 있었다. cNN 하려면 설계도 그려러봐라.\n","# 풀링하면 화소수 변화가 있었다. 반으로 줄었어. 채널수는 변화가 없었어. 몇개? 32개. 채널수는 그림개수.\n","# 이거 숫자 세개 다 이해해야해. \n","# 이거 다 이해해야해. 28,28,1 and 28,28,32 and 14,14,32\n","# 컨볼루션해서채널 64로 늘렸어.\n","# 화소수 14에서 7로 코딩한번 더할거야.\n","# 두번째 합성곱 블럭 추가 - 여러분이 직접해봐 - 64로만 바꾸면 돼\n","model.add(Conv2D(filters=64, \n","                 kernel_size=2,\n","                 padding='same',\n","                 activation='relu')) \n","\n","model.add(MaxPool2D(pool_size=2)) # 반으로 줄어들어, 화소의 축소\n","# 컨볼루션 : 필터를 곱한다. 학습이 일어나는 과정\n","# 풀링 : 화소를 버린다.\n","          \n","# 화소를 뉴런화 할거다\n","# 그러면 뉴런이 몇개 생기는가? 답 : 7곱7곱 64 = 3136개 생긴다.\n","\n","# 세번쨰 : 화소를 뉴런으로 전환 - flatten : 납작하게 하다\n","# 플래튼 기준 전반부 후반부 나눔\n","model.add(Flatten()) # 1차원전환\n","# 앞부분은 특징 추출하고 화소 줄이는게 앞부분에서 하는거다.\n","# 뒷부분에서는 결론을 내야해. FC는 fully connected 덴스 레이어다.\n","# 뒷부분 : 뉴런수 줄이기\n","# 3136\n","# 왜 출력 뉴런이 10개냐? 답 : 아이템이 10개다. \n","# 왜 하나가 아니라 10개냐? 답 : 하나면 평균을 출력해서 정확한 값이 뭔지 모를 수 있다.\n","# 출력라벨은 원핫인코딩했다.\n","# 원핫인코딩된 답 10개와 정답 10개와 비교할거야.\n","\n","# 첫번째 은닉층\n","model.add(Dense(units=128,\n","                activation='relu')) # 처음에 128개로 줄인다\n","\n","# 출력층 \n","model.add(Dense(units=10,\n","                activation='softmax')) # 확률 10개 계산해주는 활성화 함수\n","# 낯선 것을 반복해서 익숙하게 만들어라\n","# 소프트 맥스 판서를 참고하라.'\n","# 입력값을 확률로 다 전환시켜준다 : 소프트 맥스\n","# CNN = 컨볼ㄹ루션+풀링 +DNN\n","# 주어진 이미지의 라벨이 0일 확률부터 주어진 이미지의 라벨이 9일확률 10개가 출력된다.\n","# CNN : 이미지 주면 확률 10개 준다. 10개 중 가장 높은 확률을 갖는 라벨.\n","\n","# CNN 요약\n","model.summary() # 모델이 잘되었는지 확인하려면 서머리를 해라.\n","\n","# Total params: 411,242 수치가 일치해야 정상작으로 작동된거다.\n","\n","# 서머리 : 784개에서 10개로 축소하는 과정\n"," "],"metadata":{"id":"L1dmM2gXMhNY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641533645189,"user_tz":-540,"elapsed":383,"user":{"displayName":"IRUM KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12875629916024573944"}},"outputId":"4bbe1296-570c-4a79-f70a-ccafd744ed11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 28, 28, 32)        160       \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 14, 14, 64)        8256      \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 7, 7, 64)         0         \n"," 2D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 3136)              0         \n","                                                                 \n"," dense (Dense)               (None, 128)               401536    \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                1290      \n","                                                                 \n","=================================================================\n","Total params: 411,242\n","Trainable params: 411,242\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# 8번 셀\n","\n","# CNN 학습\n","# 1. 학습 환경 설정 :model.compile(), \n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['acc'])\n","\n","# 크로스 엔트로피에 대한 설명\n","# 크로스 엔트로피 손실함수 강의자료를 참고하시오. 요즘 굉장히 많이 쓴다.\n","# S(Y)는 예측값이다. 어떤 활성화를 거쳤는가? 답 : 소프트맥스\n","# 예측값은 확률로, 정답은 원핫 인코딩인 상황에 딱 맞는 손실함수 : 크로스엔트로피\n","# 내생각 : 손실함수 따로 빼서 공부하자\n","# 판서 교차엔트로피를 참고사히송.\n","# xentropy : 행렬이 아니라 합의 결과에 마이너스를 곱한다는 의미.\n","# 정답 위치에 있는 예측값만 보면 된다. 나머지는 0이다. 크로스 엔트로피는 100만개여도 하나만 보면 된다.\n","# 사람들이 많이쓴다. 계산이 엄청 빠르기 때문이다.\n","# 로그의 베이스는 10이다. \n","# x=0.1이면\n","# x의 범위는 [0,1]이다. x는 확률이기 때문이다.\n","# 틀렸는데 얼만큼 틀렸나? \n","# x가 0이면 y는 inf, x가 1이면 y는 0이다.\n","# 로그를 취하는 위치가 0이면 완벽하게 틀려서 에러가 1이고 \n","# 로그를 취하는 위치가 1이면 완벽하게 맞아서 에러가 0이다.\n","# 이런 함수가 좋은 loss 함수이다.\n","# 틀린 것에 대해 벌주는게 mae는 약하다\n","# 크로스 엔트로피는 틀리면 벌이 무한대야. 이런 분위기에서는 틀릴 수가 없다.\n","# 좋은 손실함수의 요건\n","# 1. 계싼이 빠를 것.\n","# 2. 에러가 커지면 손실값도 커질 것\n","# 틀리지 말라고 하는건 맞추라는 의미.\n","\n","\n","# adam은 3번째 테마에서 설명한다.\n","\n","# 2. 반복 학습 진행 : model.fit()\n","print('학습시작')\n","begin = time()\n","\n","model.fit(X_train,\n","          Y_train,\n","          epochs=MY_EPOCH,\n","          batch_size=MY_BATCH,\n","          verbose=1)\n","# verbose : 반복할 떄마다 진행상황을 보여준다. 1이여야 보여주고 0이면 안보여준다. 1000번 만번 돌리면 0으로 꺼버린다.\n","\n","end = time()\n","print('총 학습 시간 : ', end-begin)\n","# 이제 데이터 6만개다. 학습시간이 오래걸린다.\n","# 수정 / 노트설정 / GPU\n","# TPU : 구글이 자체제작한 ai 반도체. gpu보다 느리다. tpu 우선순위는 자기네들 서비스기 때문이다.\n","# CO PRO : 한달에 몇만원. 학습속도 18초 나온다. 우리느 41초 나온다.\n","\n","# adam은 무엇인가"],"metadata":{"id":"GfbEFgaWYOra","executionInfo":{"status":"ok","timestamp":1641533687306,"user_tz":-540,"elapsed":42120,"user":{"displayName":"IRUM KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12875629916024573944"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3039d89b-0d30-461f-9f6e-717b1b9cc488"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["학습시작\n","Epoch 1/10\n","120/120 [==============================] - 5s 24ms/step - loss: 0.6723 - acc: 0.7613\n","Epoch 2/10\n","120/120 [==============================] - 3s 24ms/step - loss: 0.3953 - acc: 0.8596\n","Epoch 3/10\n","120/120 [==============================] - 3s 23ms/step - loss: 0.3470 - acc: 0.8780\n","Epoch 4/10\n","120/120 [==============================] - 3s 23ms/step - loss: 0.3160 - acc: 0.8868\n","Epoch 5/10\n","120/120 [==============================] - 3s 23ms/step - loss: 0.2953 - acc: 0.8951\n","Epoch 6/10\n","120/120 [==============================] - 3s 23ms/step - loss: 0.2814 - acc: 0.8988\n","Epoch 7/10\n","120/120 [==============================] - 3s 23ms/step - loss: 0.2633 - acc: 0.9060\n","Epoch 8/10\n","120/120 [==============================] - 3s 23ms/step - loss: 0.2503 - acc: 0.9100\n","Epoch 9/10\n","120/120 [==============================] - 3s 23ms/step - loss: 0.2421 - acc: 0.9122\n","Epoch 10/10\n","120/120 [==============================] - 3s 23ms/step - loss: 0.2326 - acc: 0.9159\n","총 학습 시간 :  41.87203335762024\n"]}]},{"cell_type":"code","source":["# 9번셀\n","\n","# CNN 평가\n","# 10000개 시험\n","score = model.evaluate(X_test, \n","                       Y_test)\n","\n","# print(score)\n","# 성적이 두개 나온다. 왜 두개 나오는가? 답 : \n","# 첫번째 값은 최종 손실값이다. 크로스엔트로피 값이다. 별로 의미없는 값이다.\n","# 두번째는 정확도이다.\n","print('최종 정확도 : ',score[1]) # 10000개 중 9천개는 양호한 수준이다.\n","# 뭐를 맞고 뭐를 틀렸는가? 10번 셀로"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wr9KKWWL7iY7","executionInfo":{"status":"ok","timestamp":1641533688802,"user_tz":-540,"elapsed":1521,"user":{"displayName":"IRUM KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12875629916024573944"}},"outputId":"a755c534-cee9-4d88-c310-7a2ff58a8f4d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 2s 4ms/step - loss: 0.2869 - acc: 0.8964\n","최종 정확도 :  0.896399974822998\n"]}]},{"cell_type":"markdown","source":["import numpy as np\n","\n","arr = np.array([[1], [2], [3]])\n","\n","expansion = np.expand_dims(arr, axis=0)\n","reduction = np.squeeze(arr, axis=1)\n","\n","print(arr)\n","print(expansion)\n","print(reduction)\n","\n","https://076923.github.io/posts/Python-numpy-9/"],"metadata":{"id":"7RwXUI0qWY73"}},{"cell_type":"code","source":["# 10번 셀\n","\n","# 샘플 결과 출력\n","print(X_test[0].shape)\n","# plt.imshow(X_test[0]) # TypeError: Invalid shape (28, 28, 1) for image data : 왜 에러가 났을까.shape.  답: imshow로 찍으려면 2차원이여야하지만 3차원이다.\n","# 구체적으로2차원 (28,28)로 바꿔줘야한다.\n","# imshow를 사용하려면 채널 정보가 있으면 안된다.\n","\n","# imshow 함수는 채널 정보를 제거해야함\n","# (28,28,1) -> (28,28) : \n","# 방법1 : np.reshape() -> 이것보다 쉬운방법이 방법2다\n","# 방법2 : squeeze\n","# 방버 3 : img = X_test[0].squeeze() 도 가능하다.스퀴즈 써서 채널정보 빼준다.\n","img = np.squeeze(X_test[0])\n","print(img.shape)\n","plt.imshow(img)\n","\n","print('라벨 : ',Y_test[0]) # X_test[0]은 anckle boots이다. 정답이 라벨 9이라는 의미이다.\n","# 이제 기계가 뭐라고 예측했느지 확인해보자\n","pred = model.predict(X_test) # \n","# print('CNN 예측 : ', pred[0]) # X_test[0]이 아니다\n","# 왜 예측값이 10개나 만들었을까? 답 : 라벨 각각의 확률을 의미한다. 이게 확률 10개다. \n","# 예측값이 9.97445703e-01가 가장 크므로 라벨 9일 확률이 가장 크다는 의미이다. 따라서 맞았다.\n","# 이렇게 10개 다 주지 말고 9번째가 가장 커요라고 말해주는 명령어를 아는 사람 ? 답 : \n","# max(pred[0])이 아니고 argmax이다. 코딩은 다음과 같이한다.\n","print('CNN 예측 : ', np.argmax(pred[0])) # 9를 반환하므로 10개 중 라벨 9가 가장크다고 말해주는 거다.\n","# 제일 큰게 몇번쨰에 있는지 알려주는 함수다.\n","# 낯선 것을 반복해서 익숙하게 만들어라"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":338},"id":"mp80aLhF7xlQ","executionInfo":{"status":"ok","timestamp":1641534466903,"user_tz":-540,"elapsed":1259,"user":{"displayName":"IRUM KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12875629916024573944"}},"outputId":"ea8b26d9-f55b-429b-a3aa-71ceedd51d89"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(28, 28, 1)\n","(28, 28)\n","라벨 :  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n","CNN 예측 :  9\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["# 합성곱 신경망을 이용한 이미지 인식"],"metadata":{"id":"RAl5kzBy8hi-"},"execution_count":null,"outputs":[]}]}