{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4. 영화 (1)","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP64inHQpn4iaIRXh8HxXfO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"HHWIoKUXUA_j","executionInfo":{"status":"ok","timestamp":1641904791029,"user_tz":-540,"elapsed":2885,"user":{"displayName":"IRUM KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12875629916024573944"}}},"outputs":[],"source":["# 1번 셀\n","\n","# 패키지 수입 \n","import numpy as np\n","from  keras.datasets import imdb\n","from keras.preprocessing.sequence import pad_sequences\n","from time import time\n","\n","from keras.models import Sequential\n","from keras.layers import Dense, Embedding, LSTM\n","from sklearn.metrics import confusion_matrix, f1_score"]},{"cell_type":"code","source":["# 2번 셀\n","\n","# 하이퍼 파라미터 설정 : RNN 설계도 참고하면 이해가 수월하다.\n","MY_WORDS = 5000    # 사전 안에 단어 수 <----------- 무슨 사전인가? \n","MY_LEN = 200        # 영화평 길이 \n","MY_EMBED = 32      # 임베딩 차원\n","MY_HIDDEN = 64     # LSTM층 차원\n","\n","MY_EPOCH = 10      # 반복 학습 수 \n","MY_BATCH = 200     # 한번에 처리하는 데이터 수"],"metadata":{"id":"7gyYfaYeUNKr","executionInfo":{"status":"ok","timestamp":1641904791030,"user_tz":-540,"elapsed":5,"user":{"displayName":"IRUM KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12875629916024573944"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# 3번 셀\n","\n","# 데이터 불러오기 : keras가 사분할 해놓은 데이터 \n","# 총 5만개 데이터. 학습용 2.5만개, 평가용 2.5만개.\n","(X_train, Y_train), (X_test, Y_test) = imdb.load_data(num_words=MY_WORDS)\n","\n","print(type(X_train))\n","print(X_train.shape)  # (25000, ) : 1차원 데이터. Day-6 판서 참고하시오.\n","print(Y_train.shape)  # 감성 : 0이면 부정, 1이면 긍정 -> 이진분류문제\n","\n","print('0번학습용 입력 데이터(영화평) : ', X_train[0]) # 단어가 아닌 숫자 -> Token 처리된 (정수)영화평 -> 정수를 단어로 전환하기 \n","print('0번학습용 출력 데이터(감성평) : ', Y_train[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FwsU0TQ_jaOK","executionInfo":{"status":"ok","timestamp":1641904795955,"user_tz":-540,"elapsed":4929,"user":{"displayName":"IRUM KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12875629916024573944"}},"outputId":"7c8b2d57-0c1e-442c-9872-77997a780b46"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'numpy.ndarray'>\n","(25000,)\n","(25000,)\n","0번학습용 입력 데이터(영화평) :  [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 2, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n","0번학습용 출력 데이터(감성평) :  1\n"]}]},{"cell_type":"markdown","source":["RNN으로 영화평 감성 분석하기 2022년 1월 10일 김이룸"],"metadata":{"id":"6_amI2SPUGKP"}},{"cell_type":"code","source":["# 4번 셀\n","\n","# 단어를 정수로 전환하기\n","word_to_id = imdb.get_word_index()  # 단어들의 사전, 단어를 입력하면  정수 인덱스(id)를 반환하는 imdb 함수\n","print('the의 token(id) : ', word_to_id['the'])\n","print('and의 token(id) : ', word_to_id['and'])\n","\n","\n","# 정수를 단어로 전환하기\n","id_to_word = {} \n","for word, id in word_to_id.items():\n","  id_to_word[id] = word\n","\n","print('Token 1의 단어(word) : ',  id_to_word[1])\n","print('Token 2의 단어(word) : ',  id_to_word[2])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LrQMvWVhkt17","executionInfo":{"status":"ok","timestamp":1641904795955,"user_tz":-540,"elapsed":9,"user":{"displayName":"IRUM KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12875629916024573944"}},"outputId":"055227e2-9e32-44f4-9c5b-094161af74e8"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["the의 token(id) :  1\n","and의 token(id) :  2\n","Token 1의 단어(word) :  the\n","Token 2의 단어(word) :  and\n"]}]},{"cell_type":"code","source":["# 5번 셀\n","\n","# 영화평(X_train[i]) 단어로 전환하기 : id-3 & get함수로 음수(0-3, 1-3, 2-3)처리\n","# dictionary.get() : dict의 Key로 Value얻기\n","def decode(review):\n","  output = []\n","  for i in review:\n","    word = id_to_word.get(i-3, '???')\n","    output.append(word)\n","  print(output)\n","\n","decode(X_train[0])\n","print(Y_train[0])   # 1 : pos review\n","\n","decode(X_train[1])\n","print(Y_train[1])   # 0 : neg review"],"metadata":{"id":"hbQ0dFq5oRhl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641904795955,"user_tz":-540,"elapsed":7,"user":{"displayName":"IRUM KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12875629916024573944"}},"outputId":"83dec3d4-0a0a-42cb-8bf7-c4bfc7dc2bf1"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["['???', 'this', 'film', 'was', 'just', 'brilliant', 'casting', 'location', 'scenery', 'story', 'direction', \"everyone's\", 'really', 'suited', 'the', 'part', 'they', 'played', 'and', 'you', 'could', 'just', 'imagine', 'being', 'there', 'robert', '???', 'is', 'an', 'amazing', 'actor', 'and', 'now', 'the', 'same', 'being', 'director', '???', 'father', 'came', 'from', 'the', 'same', 'scottish', 'island', 'as', 'myself', 'so', 'i', 'loved', 'the', 'fact', 'there', 'was', 'a', 'real', 'connection', 'with', 'this', 'film', 'the', 'witty', 'remarks', 'throughout', 'the', 'film', 'were', 'great', 'it', 'was', 'just', 'brilliant', 'so', 'much', 'that', 'i', 'bought', 'the', 'film', 'as', 'soon', 'as', 'it', 'was', 'released', 'for', '???', 'and', 'would', 'recommend', 'it', 'to', 'everyone', 'to', 'watch', 'and', 'the', 'fly', '???', 'was', 'amazing', 'really', 'cried', 'at', 'the', 'end', 'it', 'was', 'so', 'sad', 'and', 'you', 'know', 'what', 'they', 'say', 'if', 'you', 'cry', 'at', 'a', 'film', 'it', 'must', 'have', 'been', 'good', 'and', 'this', 'definitely', 'was', 'also', '???', 'to', 'the', 'two', 'little', '???', 'that', 'played', 'the', '???', 'of', 'norman', 'and', 'paul', 'they', 'were', 'just', 'brilliant', 'children', 'are', 'often', 'left', 'out', 'of', 'the', '???', 'list', 'i', 'think', 'because', 'the', 'stars', 'that', 'play', 'them', 'all', 'grown', 'up', 'are', 'such', 'a', 'big', '???', 'for', 'the', 'whole', 'film', 'but', 'these', 'children', 'are', 'amazing', 'and', 'should', 'be', '???', 'for', 'what', 'they', 'have', 'done', \"don't\", 'you', 'think', 'the', 'whole', 'story', 'was', 'so', 'lovely', 'because', 'it', 'was', 'true', 'and', 'was', \"someone's\", 'life', 'after', 'all', 'that', 'was', '???', 'with', 'us', 'all']\n","1\n","['???', 'big', 'hair', 'big', '???', 'bad', 'music', 'and', 'a', 'giant', 'safety', '???', 'these', 'are', 'the', 'words', 'to', 'best', 'describe', 'this', 'terrible', 'movie', 'i', 'love', 'cheesy', 'horror', 'movies', 'and', \"i've\", 'seen', 'hundreds', 'but', 'this', 'had', 'got', 'to', 'be', 'on', 'of', 'the', 'worst', 'ever', 'made', 'the', 'plot', 'is', 'paper', 'thin', 'and', 'ridiculous', 'the', 'acting', 'is', 'an', '???', 'the', 'script', 'is', 'completely', 'laughable', 'the', 'best', 'is', 'the', 'end', 'showdown', 'with', 'the', 'cop', 'and', 'how', 'he', 'worked', 'out', 'who', 'the', 'killer', 'is', \"it's\", 'just', 'so', 'damn', 'terribly', 'written', 'the', 'clothes', 'are', '???', 'and', 'funny', 'in', 'equal', '???', 'the', 'hair', 'is', 'big', 'lots', 'of', '???', '???', 'men', 'wear', 'those', 'cut', '???', '???', 'that', 'show', 'off', 'their', '???', '???', 'that', 'men', 'actually', 'wore', 'them', 'and', 'the', 'music', 'is', 'just', '???', 'trash', 'that', 'plays', 'over', 'and', 'over', 'again', 'in', 'almost', 'every', 'scene', 'there', 'is', 'trashy', 'music', '???', 'and', '???', 'taking', 'away', 'bodies', 'and', 'the', '???', 'still', \"doesn't\", 'close', 'for', '???', 'all', '???', 'aside', 'this', 'is', 'a', 'truly', 'bad', 'film', 'whose', 'only', 'charm', 'is', 'to', 'look', 'back', 'on', 'the', 'disaster', 'that', 'was', 'the', \"80's\", 'and', 'have', 'a', 'good', 'old', 'laugh', 'at', 'how', 'bad', 'everything', 'was', 'back', 'then']\n","0\n"]}]},{"cell_type":"code","source":["# 6번 셀\n","\n","# 영화평 길이 확인 : 천차만별\n","for i in range(5):\n","  print(i, '번 영화평 길이 : ', len(X_train[i]))\n","\n","\n","# 영화평(X_train, X_test) 길이 통일 : pad_sequence 함수 사용\n","# truncating='pre' : 앞부분 자르기\n","# truncating='post' : 뒷부분 자르기\n","# padding='pre' : 앞부분에 패딩처리. 앞부분을 (CNN padding='same'처럼)0으로 채우는 것.\n","# padding='post' : 뒷부분에 패딩처리. 뒷부분을 0으로 채우는 것.\n","# maxlen : 통일할 영화평의 길이 지정 -> 긴거는 자르고, 짧은 거는 (0으로) 채우기\n","X_train = pad_sequences(X_train,\n","                        truncating='pre',\n","                        padding='pre',\n","                        maxlen=MY_LEN)\n","\n","X_test = pad_sequences(X_test,\n","                      truncating='pre',\n","                      padding='pre',\n","                      maxlen=MY_LEN)\n","\n","\n","# 영화평 길이 확인 \n","for i in range(5):\n","  print(i, '번 영화평 길이 : ', len(X_train[i]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"co0igQ2aCDm5","executionInfo":{"status":"ok","timestamp":1641904797403,"user_tz":-540,"elapsed":1453,"user":{"displayName":"IRUM KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12875629916024573944"}},"outputId":"ab580eff-0ee9-462d-c46c-90eaea4cb51d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["0 번 영화평 길이 :  218\n","1 번 영화평 길이 :  189\n","2 번 영화평 길이 :  141\n","3 번 영화평 길이 :  550\n","4 번 영화평 길이 :  147\n","0 번 영화평 길이 :  200\n","1 번 영화평 길이 :  200\n","2 번 영화평 길이 :  200\n","3 번 영화평 길이 :  200\n","4 번 영화평 길이 :  200\n"]}]},{"cell_type":"code","source":["# 7번 셀\n","\n","# 데이터 모양 확인 : RNN 설계도 참고\n","# 입력 데이터는 1차원에서 2차원으로 변함. 길이 통일시키면서 변함.\n","print('학습용 입력 데이터 모양 : ', X_train.shape )\n","print('학습용 출력 데이터 모양 : ', Y_train.shape )\n","print('평가용 입력 데이터 모양 : ', X_test.shape )\n","print('평가용 출력 데이터 모양 : ', Y_test.shape )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KISiUbO6DEdQ","executionInfo":{"status":"ok","timestamp":1641904797403,"user_tz":-540,"elapsed":3,"user":{"displayName":"IRUM KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12875629916024573944"}},"outputId":"4352db41-a3c0-4348-ec1b-75cb82e27a6c"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["학습용 입력 데이터 모양 :  (25000, 200)\n","학습용 출력 데이터 모양 :  (25000,)\n","평가용 입력 데이터 모양 :  (25000, 200)\n","평가용 출력 데이터 모양 :  (25000,)\n"]}]},{"cell_type":"code","source":["# 8번 셀\n","\n","# RNN 구현 : 입력은 단어 80개, 출력은 [0,1] 확률\n","model = Sequential()\n","\n","# 임베딩층 add\n","model.add(Embedding(input_dim=MY_WORDS,\n","                    output_dim=MY_EMBED,\n","                    input_length=MY_LEN))\n","\n","# LSTM층 add\n","model.add(LSTM(units=MY_HIDDEN))\n","\n","# 출력층 add\n","model.add(Dense(units=1,\n","                activation='sigmoid'))\n","\n","# RNN 요약\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Kth37FyFW4S","executionInfo":{"status":"ok","timestamp":1641904798454,"user_tz":-540,"elapsed":1053,"user":{"displayName":"IRUM KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12875629916024573944"}},"outputId":"a808e6a3-78be-4fb6-f077-dffebb21c731"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 200, 32)           160000    \n","                                                                 \n"," lstm (LSTM)                 (None, 64)                24832     \n","                                                                 \n"," dense (Dense)               (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 184,897\n","Trainable params: 184,897\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# 9번 셀\n","\n","# RNN 학습\n","model.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['acc'])\n","\n","print('학습 시작')\n","begin = time()\n","\n","model.fit(X_train,\n","          Y_train,\n","          epochs=MY_EPOCH,\n","          batch_size=MY_BATCH,\n","          verbose=1)\n","\n","end = time()\n","print('총 학습 시간 : ', end - begin)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TVepmGskHC5p","executionInfo":{"status":"ok","timestamp":1641904868919,"user_tz":-540,"elapsed":70468,"user":{"displayName":"IRUM KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12875629916024573944"}},"outputId":"3b344f57-790a-41eb-9af2-61308f17d514"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["학습 시작\n","Epoch 1/10\n","125/125 [==============================] - 9s 54ms/step - loss: 0.5790 - acc: 0.6874\n","Epoch 2/10\n","125/125 [==============================] - 7s 53ms/step - loss: 0.2950 - acc: 0.8804\n","Epoch 3/10\n","125/125 [==============================] - 7s 55ms/step - loss: 0.2429 - acc: 0.9082\n","Epoch 4/10\n","125/125 [==============================] - 7s 55ms/step - loss: 0.2103 - acc: 0.9186\n","Epoch 5/10\n","125/125 [==============================] - 7s 54ms/step - loss: 0.1823 - acc: 0.9320\n","Epoch 6/10\n","125/125 [==============================] - 7s 55ms/step - loss: 0.1670 - acc: 0.9384\n","Epoch 7/10\n","125/125 [==============================] - 7s 54ms/step - loss: 0.1559 - acc: 0.9415\n","Epoch 8/10\n","125/125 [==============================] - 7s 55ms/step - loss: 0.1358 - acc: 0.9500\n","Epoch 9/10\n","125/125 [==============================] - 7s 54ms/step - loss: 0.1227 - acc: 0.9566\n","Epoch 10/10\n","125/125 [==============================] - 7s 54ms/step - loss: 0.1116 - acc: 0.9604\n","총 학습 시간 :  70.56662940979004\n"]}]},{"cell_type":"code","source":["# 10번 셀\n","\n","# RNN 평가\n","score = model.evaluate(X_test,\n","                       Y_test)\n","\n","print('최종 정확도 : ', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XOW7CyxdHpz9","executionInfo":{"status":"ok","timestamp":1641904881547,"user_tz":-540,"elapsed":12640,"user":{"displayName":"IRUM KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12875629916024573944"}},"outputId":"99134540-cc5b-4977-e3db-14a6e1bda045"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["782/782 [==============================] - 12s 15ms/step - loss: 0.4054 - acc: 0.8440\n","최종 정확도 :  0.8439599871635437\n"]}]},{"cell_type":"code","source":["# 11번 셀\n","\n","# RNN 예측\n","pred = model.predict(X_test)\n","\n","# 평가용 데이터 샘플 예측\n","print('영화평 : ', decode(X_test[1]))\n","print('정답 : ', Y_test[1])\n","print('예측 : ', pred[1]) # [0,1] 사이 확률값 반환 -> 0.5보다 크면 1(긍정), 0.5보다 작으면 0(긍정)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T7a_zzLaH8fh","executionInfo":{"status":"ok","timestamp":1641904998451,"user_tz":-540,"elapsed":10544,"user":{"displayName":"IRUM KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12875629916024573944"}},"outputId":"82ca3cdd-2225-4c03-f129-2f2a06de6580"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["['psychological', '???', \"it's\", 'very', 'interesting', 'that', 'robert', '???', 'directed', 'this', 'considering', 'the', 'style', 'and', 'structure', 'of', 'his', 'other', 'films', 'still', 'the', '???', '???', 'audio', 'style', 'is', 'evident', 'here', 'and', 'there', 'i', 'think', 'what', 'really', 'makes', 'this', 'film', 'work', 'is', 'the', 'brilliant', 'performance', 'by', '???', 'dennis', \"it's\", 'definitely', 'one', 'of', 'her', 'darker', 'characters', 'but', 'she', 'plays', 'it', 'so', 'perfectly', 'and', 'convincingly', 'that', \"it's\", 'scary', 'michael', 'burns', 'does', 'a', 'good', 'job', 'as', 'the', '???', 'young', 'man', 'regular', '???', 'player', 'michael', 'murphy', 'has', 'a', 'small', 'part', 'the', '???', 'moody', 'set', 'fits', 'the', 'content', 'of', 'the', 'story', 'very', 'well', 'in', 'short', 'this', 'movie', 'is', 'a', 'powerful', 'study', 'of', '???', 'sexual', '???', 'and', 'desperation', 'be', 'patient', '???', 'up', 'the', 'atmosphere', 'and', 'pay', 'attention', 'to', 'the', 'wonderfully', 'written', 'script', 'br', 'br', 'i', 'praise', 'robert', '???', 'this', 'is', 'one', 'of', 'his', 'many', 'films', 'that', 'deals', 'with', '???', 'fascinating', 'subject', 'matter', 'this', 'film', 'is', 'disturbing', 'but', \"it's\", 'sincere', 'and', \"it's\", 'sure', 'to', '???', 'a', 'strong', 'emotional', 'response', 'from', 'the', 'viewer', 'if', 'you', 'want', 'to', 'see', 'an', 'unusual', 'film', 'some', 'might', 'even', 'say', 'bizarre', 'this', 'is', 'worth', 'the', 'time', 'br', 'br', 'unfortunately', \"it's\", 'very', 'difficult', 'to', 'find', 'in', 'video', '???', 'you', 'may', 'have', 'to', 'buy', 'it', 'off', 'the', 'internet']\n","영화평 :  None\n","정답 :  1\n","예측 :  [0.9853757]\n"]}]},{"cell_type":"code","source":["# 12번 셀\n","\n","# 확률 결과를 이진수로 전환 : 혼동행렬 만들기 위함\n","print(pred)\n","pred = (pred > 0.5)\n","print(pred)\n","\n","# 혼동행렬\n","print(confusion_matrix(Y_test,\n","                       pred))\n","\n","# F1 점수\n","print(f1_score(Y_test,\n","               pred,\n","               average='micro'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1-mGxPa-JFbV","executionInfo":{"status":"ok","timestamp":1641905105569,"user_tz":-540,"elapsed":235,"user":{"displayName":"IRUM KIM","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12875629916024573944"}},"outputId":"85d1768d-5322-4c45-eadd-b255b0e108de"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.12727448]\n"," [0.9853757 ]\n"," [0.6273767 ]\n"," ...\n"," [0.09291574]\n"," [0.0059434 ]\n"," [0.61575145]]\n","[[False]\n"," [ True]\n"," [ True]\n"," ...\n"," [False]\n"," [False]\n"," [ True]]\n","[[10927  1573]\n"," [ 2328 10172]]\n","0.84396\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"gNhFGIfdKRQl"},"execution_count":null,"outputs":[]}]}